2018-10-10 21:33:38 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-10-10 21:33:39 INFO  SparkContext:54 - Running Spark version 2.3.1
2018-10-10 21:33:39 INFO  SparkContext:54 - Submitted application: Venmo
2018-10-10 21:33:39 INFO  SecurityManager:54 - Changing view acls to: ubuntu
2018-10-10 21:33:39 INFO  SecurityManager:54 - Changing modify acls to: ubuntu
2018-10-10 21:33:39 INFO  SecurityManager:54 - Changing view acls groups to: 
2018-10-10 21:33:39 INFO  SecurityManager:54 - Changing modify acls groups to: 
2018-10-10 21:33:39 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ubuntu); groups with view permissions: Set(); users  with modify permissions: Set(ubuntu); groups with modify permissions: Set()
2018-10-10 21:33:39 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 35758.
2018-10-10 21:33:39 INFO  SparkEnv:54 - Registering MapOutputTracker
2018-10-10 21:33:39 INFO  SparkEnv:54 - Registering BlockManagerMaster
2018-10-10 21:33:39 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-10-10 21:33:39 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2018-10-10 21:33:39 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-669bd61e-5394-44bc-9699-8d17bdaff8be
2018-10-10 21:33:39 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2018-10-10 21:33:39 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2018-10-10 21:33:39 INFO  log:192 - Logging initialized @2288ms
2018-10-10 21:33:39 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2018-10-10 21:33:39 INFO  Server:414 - Started @2370ms
2018-10-10 21:33:39 INFO  AbstractConnector:278 - Started ServerConnector@60b9ad97{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-10-10 21:33:39 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2018-10-10 21:33:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d486a8d{/jobs,null,AVAILABLE,@Spark}
2018-10-10 21:33:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@53d8e346{/jobs/json,null,AVAILABLE,@Spark}
2018-10-10 21:33:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7123aca9{/jobs/job,null,AVAILABLE,@Spark}
2018-10-10 21:33:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65c45824{/jobs/job/json,null,AVAILABLE,@Spark}
2018-10-10 21:33:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@71924509{/stages,null,AVAILABLE,@Spark}
2018-10-10 21:33:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1db8f976{/stages/json,null,AVAILABLE,@Spark}
2018-10-10 21:33:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77945bc2{/stages/stage,null,AVAILABLE,@Spark}
2018-10-10 21:33:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@926a92c{/stages/stage/json,null,AVAILABLE,@Spark}
2018-10-10 21:33:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5cb9a981{/stages/pool,null,AVAILABLE,@Spark}
2018-10-10 21:33:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5dad6f32{/stages/pool/json,null,AVAILABLE,@Spark}
2018-10-10 21:33:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7246a9fc{/storage,null,AVAILABLE,@Spark}
2018-10-10 21:33:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4e150151{/storage/json,null,AVAILABLE,@Spark}
2018-10-10 21:33:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5ff15cb3{/storage/rdd,null,AVAILABLE,@Spark}
2018-10-10 21:33:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@69137c80{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-10-10 21:33:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e5d3117{/environment,null,AVAILABLE,@Spark}
2018-10-10 21:33:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@48a4a204{/environment/json,null,AVAILABLE,@Spark}
2018-10-10 21:33:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1d656b67{/executors,null,AVAILABLE,@Spark}
2018-10-10 21:33:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6f60e337{/executors/json,null,AVAILABLE,@Spark}
2018-10-10 21:33:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2872a245{/executors/threadDump,null,AVAILABLE,@Spark}
2018-10-10 21:33:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@452b91cd{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-10-10 21:33:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7323e45c{/static,null,AVAILABLE,@Spark}
2018-10-10 21:33:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2419e3aa{/,null,AVAILABLE,@Spark}
2018-10-10 21:33:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fe5cf56{/api,null,AVAILABLE,@Spark}
2018-10-10 21:33:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f278db{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-10-10 21:33:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5fc4428d{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-10-10 21:33:40 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://ec2-107-23-227-201.compute-1.amazonaws.com:4040
2018-10-10 21:33:40 INFO  SparkContext:54 - Added file file:/home/ubuntu/ventra/src/batch_processing/spark_batch.py at spark://ip-10-0-0-7.ec2.internal:35758/files/spark_batch.py with timestamp 1539207220417
2018-10-10 21:33:40 INFO  Utils:54 - Copying /home/ubuntu/ventra/src/batch_processing/spark_batch.py to /tmp/spark-fa5368a5-0e5c-4a52-b90b-1e356c3443dd/userFiles-78b28fd4-2d37-47ec-a6f7-120a8720f163/spark_batch.py
2018-10-10 21:33:40 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://ec2-107-23-227-201.compute-1.amazonaws.com:7077...
2018-10-10 21:33:40 INFO  TransportClientFactory:267 - Successfully created connection to ec2-107-23-227-201.compute-1.amazonaws.com/10.0.0.7:7077 after 25 ms (0 ms spent in bootstraps)
2018-10-10 21:33:40 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20181010213340-0066
2018-10-10 21:33:40 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20181010213340-0066/0 on worker-20180925025414-10.0.0.8-38891 (10.0.0.8:38891) with 6 core(s)
2018-10-10 21:33:40 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20181010213340-0066/0 on hostPort 10.0.0.8:38891 with 6 core(s), 6.0 GB RAM
2018-10-10 21:33:40 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20181010213340-0066/1 on worker-20180925025413-10.0.0.11-42938 (10.0.0.11:42938) with 6 core(s)
2018-10-10 21:33:40 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20181010213340-0066/1 on hostPort 10.0.0.11:42938 with 6 core(s), 6.0 GB RAM
2018-10-10 21:33:40 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42912.
2018-10-10 21:33:40 INFO  NettyBlockTransferService:54 - Server created on ip-10-0-0-7.ec2.internal:42912
2018-10-10 21:33:40 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-10-10 21:33:40 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20181010213340-0066/1 is now RUNNING
2018-10-10 21:33:40 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20181010213340-0066/0 is now RUNNING
2018-10-10 21:33:40 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, ip-10-0-0-7.ec2.internal, 42912, None)
2018-10-10 21:33:40 INFO  BlockManagerMasterEndpoint:54 - Registering block manager ip-10-0-0-7.ec2.internal:42912 with 366.3 MB RAM, BlockManagerId(driver, ip-10-0-0-7.ec2.internal, 42912, None)
2018-10-10 21:33:40 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, ip-10-0-0-7.ec2.internal, 42912, None)
2018-10-10 21:33:40 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, ip-10-0-0-7.ec2.internal, 42912, None)
2018-10-10 21:33:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@58ecb087{/metrics/json,null,AVAILABLE,@Spark}
2018-10-10 21:33:40 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2018-10-10 21:33:41 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 237.8 KB, free 366.1 MB)
2018-10-10 21:33:41 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.2 KB, free 366.0 MB)
2018-10-10 21:33:41 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on ip-10-0-0-7.ec2.internal:42912 (size: 23.2 KB, free: 366.3 MB)
2018-10-10 21:33:41 INFO  SparkContext:54 - Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:0
2018-10-10 21:33:42 INFO  FileInputFormat:249 - Total input paths to process : 2
2018-10-10 21:33:42 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.0.11:49926) with ID 1
2018-10-10 21:33:42 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.0.11:33021 with 3.0 GB RAM, BlockManagerId(1, 10.0.0.11, 33021, None)
2018-10-10 21:33:42 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.0.8:36726) with ID 0
2018-10-10 21:33:42 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.0.8:45068 with 3.0 GB RAM, BlockManagerId(0, 10.0.0.8, 45068, None)
2018-10-10 21:33:42 INFO  SparkContext:54 - Starting job: collect at /home/ubuntu/ventra/src/batch_processing/spark_batch.py:150
2018-10-10 21:33:43 INFO  DAGScheduler:54 - Registering RDD 3 (reduceByKey at /home/ubuntu/ventra/src/batch_processing/spark_batch.py:129)
2018-10-10 21:33:43 INFO  DAGScheduler:54 - Got job 0 (collect at /home/ubuntu/ventra/src/batch_processing/spark_batch.py:150) with 2 output partitions
2018-10-10 21:33:43 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (collect at /home/ubuntu/ventra/src/batch_processing/spark_batch.py:150)
2018-10-10 21:33:43 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 0)
2018-10-10 21:33:43 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 0)
2018-10-10 21:33:43 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 0 (PairwiseRDD[3] at reduceByKey at /home/ubuntu/ventra/src/batch_processing/spark_batch.py:129), which has no missing parents
2018-10-10 21:33:43 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 11.3 KB, free 366.0 MB)
2018-10-10 21:33:43 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.2 KB, free 366.0 MB)
2018-10-10 21:33:43 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on ip-10-0-0-7.ec2.internal:42912 (size: 7.2 KB, free: 366.3 MB)
2018-10-10 21:33:43 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2018-10-10 21:33:43 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[3] at reduceByKey at /home/ubuntu/ventra/src/batch_processing/spark_batch.py:129) (first 15 tasks are for partitions Vector(0, 1))
2018-10-10 21:33:43 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 2 tasks
2018-10-10 21:33:43 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, 10.0.0.8, executor 0, partition 0, PROCESS_LOCAL, 7886 bytes)
2018-10-10 21:33:43 INFO  TaskSetManager:54 - Starting task 1.0 in stage 0.0 (TID 1, 10.0.0.11, executor 1, partition 1, PROCESS_LOCAL, 7886 bytes)
2018-10-10 21:33:43 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 10.0.0.8:45068 (size: 7.2 KB, free: 3.0 GB)
2018-10-10 21:33:43 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 10.0.0.11:33021 (size: 7.2 KB, free: 3.0 GB)
2018-10-10 21:33:43 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 10.0.0.8:45068 (size: 23.2 KB, free: 3.0 GB)
2018-10-10 21:33:43 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 10.0.0.11:33021 (size: 23.2 KB, free: 3.0 GB)
2018-10-10 21:33:45 INFO  TaskSetManager:54 - Finished task 1.0 in stage 0.0 (TID 1) in 2370 ms on 10.0.0.11 (executor 1) (1/2)
2018-10-10 21:33:45 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 2512 ms on 10.0.0.8 (executor 0) (2/2)
2018-10-10 21:33:45 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-10-10 21:33:45 INFO  DAGScheduler:54 - ShuffleMapStage 0 (reduceByKey at /home/ubuntu/ventra/src/batch_processing/spark_batch.py:129) finished in 2.597 s
2018-10-10 21:33:45 INFO  DAGScheduler:54 - looking for newly runnable stages
2018-10-10 21:33:45 INFO  DAGScheduler:54 - running: Set()
2018-10-10 21:33:45 INFO  DAGScheduler:54 - waiting: Set(ResultStage 1)
2018-10-10 21:33:45 INFO  DAGScheduler:54 - failed: Set()
2018-10-10 21:33:45 INFO  DAGScheduler:54 - Submitting ResultStage 1 (PythonRDD[14] at collect at /home/ubuntu/ventra/src/batch_processing/spark_batch.py:150), which has no missing parents
2018-10-10 21:33:45 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 7.1 KB, free 366.0 MB)
2018-10-10 21:33:45 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.5 KB, free 366.0 MB)
2018-10-10 21:33:45 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on ip-10-0-0-7.ec2.internal:42912 (size: 4.5 KB, free: 366.3 MB)
2018-10-10 21:33:45 INFO  SparkContext:54 - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2018-10-10 21:33:45 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ResultStage 1 (PythonRDD[14] at collect at /home/ubuntu/ventra/src/batch_processing/spark_batch.py:150) (first 15 tasks are for partitions Vector(0, 1))
2018-10-10 21:33:45 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 2 tasks
2018-10-10 21:33:45 INFO  TaskSetManager:54 - Starting task 1.0 in stage 1.0 (TID 2, 10.0.0.8, executor 0, partition 1, NODE_LOCAL, 7653 bytes)
2018-10-10 21:33:45 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 3, 10.0.0.11, executor 1, partition 0, NODE_LOCAL, 7653 bytes)
2018-10-10 21:33:45 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 10.0.0.11:33021 (size: 4.5 KB, free: 3.0 GB)
2018-10-10 21:33:45 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 10.0.0.8:45068 (size: 4.5 KB, free: 3.0 GB)
2018-10-10 21:33:45 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 0 to 10.0.0.11:49926
2018-10-10 21:33:45 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 0 to 10.0.0.8:36726
2018-10-10 21:33:45 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 3) in 207 ms on 10.0.0.11 (executor 1) (1/2)
2018-10-10 21:33:45 INFO  TaskSetManager:54 - Finished task 1.0 in stage 1.0 (TID 2) in 219 ms on 10.0.0.8 (executor 0) (2/2)
2018-10-10 21:33:45 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-10-10 21:33:45 INFO  DAGScheduler:54 - ResultStage 1 (collect at /home/ubuntu/ventra/src/batch_processing/spark_batch.py:150) finished in 0.239 s
2018-10-10 21:33:45 INFO  DAGScheduler:54 - Job 0 finished: collect at /home/ubuntu/ventra/src/batch_processing/spark_batch.py:150, took 2.922258 s
2018-10-10 21:33:45 INFO  SparkContext:54 - Starting job: collect at /home/ubuntu/ventra/src/batch_processing/spark_batch.py:163
2018-10-10 21:33:45 INFO  DAGScheduler:54 - Registering RDD 11 (reduceByKey at /home/ubuntu/ventra/src/batch_processing/spark_batch.py:132)
2018-10-10 21:33:45 INFO  DAGScheduler:54 - Got job 1 (collect at /home/ubuntu/ventra/src/batch_processing/spark_batch.py:163) with 2 output partitions
2018-10-10 21:33:45 INFO  DAGScheduler:54 - Final stage: ResultStage 4 (collect at /home/ubuntu/ventra/src/batch_processing/spark_batch.py:163)
2018-10-10 21:33:45 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 3)
2018-10-10 21:33:45 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 3)
2018-10-10 21:33:45 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 3 (PairwiseRDD[11] at reduceByKey at /home/ubuntu/ventra/src/batch_processing/spark_batch.py:132), which has no missing parents
2018-10-10 21:33:45 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 9.3 KB, free 366.0 MB)
2018-10-10 21:33:45 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.9 KB, free 366.0 MB)
2018-10-10 21:33:45 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on ip-10-0-0-7.ec2.internal:42912 (size: 5.9 KB, free: 366.3 MB)
2018-10-10 21:33:45 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2018-10-10 21:33:45 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 3 (PairwiseRDD[11] at reduceByKey at /home/ubuntu/ventra/src/batch_processing/spark_batch.py:132) (first 15 tasks are for partitions Vector(0, 1))
2018-10-10 21:33:45 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 2 tasks
2018-10-10 21:33:45 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 4, 10.0.0.11, executor 1, partition 0, NODE_LOCAL, 7642 bytes)
2018-10-10 21:33:45 INFO  TaskSetManager:54 - Starting task 1.0 in stage 3.0 (TID 5, 10.0.0.8, executor 0, partition 1, NODE_LOCAL, 7642 bytes)
2018-10-10 21:33:45 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on 10.0.0.8:45068 (size: 5.9 KB, free: 3.0 GB)
2018-10-10 21:33:46 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on 10.0.0.11:33021 (size: 5.9 KB, free: 3.0 GB)
2018-10-10 21:33:46 INFO  TaskSetManager:54 - Finished task 1.0 in stage 3.0 (TID 5) in 89 ms on 10.0.0.8 (executor 0) (1/2)
2018-10-10 21:33:46 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 4) in 108 ms on 10.0.0.11 (executor 1) (2/2)
2018-10-10 21:33:46 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2018-10-10 21:33:46 INFO  DAGScheduler:54 - ShuffleMapStage 3 (reduceByKey at /home/ubuntu/ventra/src/batch_processing/spark_batch.py:132) finished in 0.124 s
2018-10-10 21:33:46 INFO  DAGScheduler:54 - looking for newly runnable stages
2018-10-10 21:33:46 INFO  DAGScheduler:54 - running: Set()
2018-10-10 21:33:46 INFO  DAGScheduler:54 - waiting: Set(ResultStage 4)
2018-10-10 21:33:46 INFO  DAGScheduler:54 - failed: Set()
2018-10-10 21:33:46 INFO  DAGScheduler:54 - Submitting ResultStage 4 (PythonRDD[15] at collect at /home/ubuntu/ventra/src/batch_processing/spark_batch.py:163), which has no missing parents
2018-10-10 21:33:46 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 6.5 KB, free 366.0 MB)
2018-10-10 21:33:46 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.1 KB, free 366.0 MB)
2018-10-10 21:33:46 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on ip-10-0-0-7.ec2.internal:42912 (size: 4.1 KB, free: 366.3 MB)
2018-10-10 21:33:46 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2018-10-10 21:33:46 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ResultStage 4 (PythonRDD[15] at collect at /home/ubuntu/ventra/src/batch_processing/spark_batch.py:163) (first 15 tasks are for partitions Vector(0, 1))
2018-10-10 21:33:46 INFO  TaskSchedulerImpl:54 - Adding task set 4.0 with 2 tasks
2018-10-10 21:33:46 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 6, 10.0.0.8, executor 0, partition 0, NODE_LOCAL, 7653 bytes)
2018-10-10 21:33:46 INFO  TaskSetManager:54 - Starting task 1.0 in stage 4.0 (TID 7, 10.0.0.11, executor 1, partition 1, NODE_LOCAL, 7653 bytes)
2018-10-10 21:33:46 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on 10.0.0.8:45068 (size: 4.1 KB, free: 3.0 GB)
2018-10-10 21:33:46 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on 10.0.0.11:33021 (size: 4.1 KB, free: 3.0 GB)
2018-10-10 21:33:46 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 1 to 10.0.0.8:36726
2018-10-10 21:33:46 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 1 to 10.0.0.11:49926
2018-10-10 21:33:46 INFO  TaskSetManager:54 - Finished task 1.0 in stage 4.0 (TID 7) in 86 ms on 10.0.0.11 (executor 1) (1/2)
2018-10-10 21:33:46 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 6) in 91 ms on 10.0.0.8 (executor 0) (2/2)
2018-10-10 21:33:46 INFO  TaskSchedulerImpl:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2018-10-10 21:33:46 INFO  DAGScheduler:54 - ResultStage 4 (collect at /home/ubuntu/ventra/src/batch_processing/spark_batch.py:163) finished in 0.102 s
2018-10-10 21:33:46 INFO  DAGScheduler:54 - Job 1 finished: collect at /home/ubuntu/ventra/src/batch_processing/spark_batch.py:163, took 0.243433 s
2018-10-10 21:33:46 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2018-10-10 21:33:46 INFO  AbstractConnector:318 - Stopped Spark@60b9ad97{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-10-10 21:33:46 INFO  SparkUI:54 - Stopped Spark web UI at http://ec2-107-23-227-201.compute-1.amazonaws.com:4040
2018-10-10 21:33:46 INFO  StandaloneSchedulerBackend:54 - Shutting down all executors
2018-10-10 21:33:46 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Asking each executor to shut down
2018-10-10 21:33:46 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2018-10-10 21:33:46 INFO  MemoryStore:54 - MemoryStore cleared
2018-10-10 21:33:46 INFO  BlockManager:54 - BlockManager stopped
2018-10-10 21:33:46 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2018-10-10 21:33:46 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2018-10-10 21:33:46 INFO  SparkContext:54 - Successfully stopped SparkContext
2018-10-10 21:33:46 INFO  ShutdownHookManager:54 - Shutdown hook called
2018-10-10 21:33:46 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-fa5368a5-0e5c-4a52-b90b-1e356c3443dd/pyspark-31df7d84-291a-4ded-a9b2-7a1b5c0e15ad
2018-10-10 21:33:46 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-fa5368a5-0e5c-4a52-b90b-1e356c3443dd
2018-10-10 21:33:46 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-525f43b9-3ddc-4361-be4a-2c81655cde2e
